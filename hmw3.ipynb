{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal as mvn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('EMGaussian.data', delim_whitespace=True, header=None, names=['x', 'y'])\n",
    "test = pd.read_csv('EMGaussian.test', delim_whitespace=True, header=None, names=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, A, pi, mu, sigma):\n",
    "    (T, p) = X.shape\n",
    "    alpha = np.ones((T,K))\n",
    "    # The LOG of the messages alpha are contained in the matrix Alpha. \n",
    "    # The t-th row corresponds to the time t\n",
    "    # The k-th column corresponds to the case where the state takes the value k\n",
    "\n",
    "    # Computation of the first alpha(q_0)\n",
    "    for k in range(K):\n",
    "        # Watch out we directly use logpdf, not pdf\n",
    "        alpha[0,k] = mvn.logpdf(X[k], mu[k], sigma[k])*pi[k]\n",
    "\n",
    "    for t in range(1,T):\n",
    "        for k in range(K):\n",
    "            # Alpha message formula p9 chp 12.4 of the book\n",
    "            constant_term = mvn.logpdf(X[t-1], mu[k], sigma[k])\n",
    "            log_proba_vec = alpha[t-1] + np.log(A[:,k])\n",
    "            m = max(log_proba_vec)\n",
    "            alpha[t, k] = np.log(np.exp(log_proba_vec-m).sum()) + m + const\n",
    "            \n",
    "    return alpha\n",
    "\n",
    "def backward(X, A=A, pi=pi, mu=mu, sigma=sigma):\n",
    "    (T,p) = X.shape\n",
    "    beta = np.ones((T,K))\n",
    "    \n",
    "    # Initialization of the last time T\n",
    "    # Maybe it should be something else,\n",
    "    for k in range(K):\n",
    "        # Watch out we directly use logpdf, not pdf\n",
    "        beta[T-1,k] = mvn.logpdf(X[T-1], mu[k], sigma[k])*pi[k]\n",
    "    \n",
    "    for t in range(T-1)[::-1]:\n",
    "        for k in range(K):\n",
    "            # Beta message formula 12.30 p10 chp 12.4 of the book\n",
    "            # This time there is no constant term because the conditional probability\n",
    "            # depends on q_(t+1) the index of the sum\n",
    "            \n",
    "            # Therefore we have to run another loop to compute \n",
    "            # this cond probability for K values\n",
    "            cond_proba = [mvn.logpdf(X[t+1], mu[j], sigma[j]) for j in range(K)]\n",
    "            log_proba_vec = beta[t+1] + np.log(A[k,:]) + cond_proba\n",
    "            m = max(log_proba_vec)\n",
    "            beta[t, k] = np.log(np.exp(log_proba_vec-m).sum()) + m \n",
    "            \n",
    "    return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data)\n",
    "(T,p) = data.shape\n",
    "K = 4 # Number of states (assumed)\n",
    "\n",
    "#parameters of the MV Gaussian in R^2\n",
    "mu = np.ones((4,2)) # Mean mu1\n",
    "sigma = [np.eye(2) for k in range(K)]\n",
    "pi = 1.0/4 * np.ones(4)\n",
    "\n",
    "# Transition matrix\n",
    "A = np.eye(K)*(1/2-1/6) + np.ones((K,K))*1/6\n",
    "\n",
    "alpha = forward(X, A, pi , mu, sigma)\n",
    "beta = backward(X)\n",
    "print('alpha : ', alpha, 'beta :', beta)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
